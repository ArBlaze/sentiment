{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973c5ac0-f057-4111-b26a-cd49e6b81880",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c8660402-d904-4fae-b855-0e28ac8d1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import requests as re\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import set_config\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "set_config(print_changed_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922dd47-c505-4877-b7ed-e12ac6d93d53",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e54ce6a6-23db-4fc4-b19b-1167a3da2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self, text, polarity):\n",
    "        self.text = text.translate(str.maketrans(' ', ' ',\n",
    "                                   string.punctuation)).replace(\"br\", \"\")\n",
    "        self.polarity = polarity\n",
    "\n",
    "\n",
    "class Features:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews.text\n",
    "        self.new_text = self.Stopwords()\n",
    "\n",
    "    def Stopwords(self):\n",
    "        sw_nltk = stopwords.words('english')\n",
    "        words = [word for word in self.reviews.split()\n",
    "                 if word.lower() not in sw_nltk]\n",
    "        new_text = \" \".join(words)\n",
    "        return new_text\n",
    "\n",
    "\n",
    "class Target:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews.polarity\n",
    "\n",
    "\n",
    "class Vectorization:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        # X_train, X_test CountVectorizer() transformations\n",
    "        self.X_train_vectors_count = self.count_vectorization()[0]\n",
    "        self.X_test_vectors_count = self.count_vectorization()[1]\n",
    "        # X_train, X_test TfidfVectorizer() transformation\n",
    "        self.X_train_vectors_tfidf = self.tfidf_vectorization()[0]\n",
    "        self.X_test_vectors_tfidf = self.tfidf_vectorization()[1]\n",
    "\n",
    "    def count_vectorization(self):\n",
    "        vectorizer = CountVectorizer()\n",
    "        X_train_vectors = vectorizer.fit_transform(self.X[0])\n",
    "        X_test_vectors = vectorizer.transform(self.X[1])\n",
    "        return (X_train_vectors, X_test_vectors)\n",
    "\n",
    "    def tfidf_vectorization(self):\n",
    "        vectorizer = TfidfVectorizer(lowercase=True, min_df=0.0001)\n",
    "        X_train_vectors = vectorizer.fit_transform(self.X[0])\n",
    "        X_test_vectors = vectorizer.transform(self.X[1])\n",
    "        return (X_train_vectors, X_test_vectors)\n",
    "\n",
    "\n",
    "class Logistic_Regression:\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = self.Model()\n",
    "\n",
    "    def Model(self):\n",
    "        clf_log = LogisticRegression(max_iter=1000)\n",
    "        clf_log.fit(self.X_train, self.y_train)\n",
    "        return (clf_log)\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.mean_score = self.mean_score()\n",
    "        self.f1_score = self.F1_score()\n",
    "\n",
    "    def mean_score(self):\n",
    "        return self.model.score(self.X_test, self.y_test)\n",
    "\n",
    "    def F1_score(self):\n",
    "        return f1_score(self.y_test, self.model.predict(self.X_test),\n",
    "                        average=None, labels=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf3ff9-66cd-4f03-ac67-2517d622804d",
   "metadata": {},
   "source": [
    "### Store negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e4f40b47-f965-45ff-8f1b-9e610fcefc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for links in os.listdir('./aclImdb_v1/aclImdb/test/neg'):\n",
    "    with open('./aclImdb_v1/aclImdb/test/neg/{}'.format(links),\n",
    "              encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            reviews.append(Review(line, 'negative'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1773428-d05d-4155-a1f9-8f598bda4d70",
   "metadata": {},
   "source": [
    "### Store positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a01228ec-69b1-44b2-b542-7fcb0c3c1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for links in os.listdir('./aclImdb_v1/aclImdb/test/pos'):\n",
    "    with open('./aclImdb_v1/aclImdb/test/pos/{}'.format(links),\n",
    "              encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            reviews.append(Review(line, 'positive'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4d297-c715-473f-83c7-2196ff51f287",
   "metadata": {},
   "source": [
    "### Shuffle the reviews so that it isn't directly positive reviews followed by negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "315681c4-eba9-4664-846a-b1d41b3eb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a585a9c-9e1c-46d8-982b-05d2c540a2b6",
   "metadata": {},
   "source": [
    "#### Seperate into X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "95651830-f239-44d1-9e39-fae9051edbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for line in reviews:\n",
    "    X.append(Features(line).new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6fdfc535-d3c6-44d4-98b9-6adb97321ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for line in reviews:\n",
    "    y.append(Target(line).reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018064e-87b2-4f0b-ad17-5a089b37ac31",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6cea7bbf-aac3-4f8d-a6ae-3e5fa67b1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd4e8c-f821-43ab-ade8-e1038eaa7a79",
   "metadata": {},
   "source": [
    "### Vectorize X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8c09f46c-1278-4a77-b98f-433ca10ef2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = Vectorization((X_train, X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb0992-7a90-4e8f-8993-3393dc49703f",
   "metadata": {},
   "source": [
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fe89d3cb-9332-4a0c-a8f0-89b6f3c7264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_bow = vectorize.X_train_vectors_count\n",
    "X_test_vectors_bow = vectorize.X_test_vectors_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca33d94-e05e-4d4e-8912-fce08c8f4f79",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "66934541-611a-4b17-9c1f-dd2e148ad27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_tfidf = vectorize.X_train_vectors_tfidf\n",
    "X_test_vectors_tfidf = vectorize.X_test_vectors_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca342107-a7b6-4072-bc87-f78ffd3cb307",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e7b2-46ad-429f-b32f-a5425deab0a3",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63ff20e2-5d43-48a9-9dbc-32dbd28c1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow = Logistic_Regression(X_train_vectors_bow, y_train).model\n",
    "model_tfidf = Logistic_Regression(X_train_vectors_tfidf, y_train).model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fdf81-4e83-4a52-b203-acbdf2f245cd",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa309ac-b379-43ab-baee-184f533213c7",
   "metadata": {},
   "source": [
    "#### Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9dc13cad-f8fb-443a-b72a-4492d096e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8865454545454545\n",
      "0.8936969696969697\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print (Metrics(model_bow, X_test_vectors_bow, y_test).mean_score)\n",
    "print (Metrics(model_tfidf, X_test_vectors_tfidf, y_test).mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6ef30-362d-4fc1-bde3-a4f780165c36",
   "metadata": {},
   "source": [
    "#### F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a03cb85c-a6ff-4db0-ad40-dd8ceffef490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88741881 0.88565844]\n",
      "[0.89555794 0.89176848]\n"
     ]
    }
   ],
   "source": [
    "print (Metrics(model_bow, X_test_vectors_bow, y_test).f1_score)\n",
    "print (Metrics(model_tfidf, X_test_vectors_tfidf, y_test).f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042839ed-ce96-41d4-ba95-fe85650ad5a6",
   "metadata": {},
   "source": [
    "##### I want to improve our scores. There are a couple of things that we can do.\n",
    "* <s>Making each string lowercase</s>\n",
    "* <s>Removing punctuation</s>\n",
    "* <s>Removing common words such as \"and\", \"to\", \"or\", \"the\", \"is\", and more</s>\n",
    "* <s>Adding weights to words</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69051ab-061f-4b52-b5a0-8a3fdcd3adc6",
   "metadata": {},
   "source": [
    "### Analyzing word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b850dc77-f5e2-41e9-9d0a-e97fd2cc0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "\n",
    "for row in X:\n",
    "    for split in row.split():\n",
    "        X1.append(split)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d483cec6-7e6b-4561-b75a-24a044f66c66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 18649),\n",
       " ('good', 13650),\n",
       " ('would', 11750),\n",
       " ('time', 11576),\n",
       " ('see', 10963),\n",
       " ('even', 10622),\n",
       " ('story', 10539),\n",
       " ('bad', 8406),\n",
       " ('great', 8297),\n",
       " ('well', 8095),\n",
       " ('make', 7507),\n",
       " ('first', 7462),\n",
       " ('made', 7409),\n",
       " ('way', 7340),\n",
       " ('could', 7325),\n",
       " ('dont', 7237),\n",
       " ('seen', 6597),\n",
       " ('character', 6443),\n",
       " ('watch', 6401),\n",
       " ('many', 6299),\n",
       " ('know', 6211),\n",
       " ('plot', 6065),\n",
       " ('acting', 6052),\n",
       " ('never', 6012),\n",
       " ('show', 5878),\n",
       " ('love', 5840),\n",
       " ('best', 5650),\n",
       " ('ever', 5646),\n",
       " ('little', 5608),\n",
       " ('life', 5551),\n",
       " ('better', 5501),\n",
       " ('end', 5144),\n",
       " ('something', 4756),\n",
       " ('still', 4670),\n",
       " ('Im', 4432),\n",
       " ('didnt', 4380),\n",
       " ('thing', 4365),\n",
       " ('real', 4350),\n",
       " ('back', 4337),\n",
       " ('man', 4305),\n",
       " ('watching', 4281),\n",
       " ('doesnt', 4276),\n",
       " ('funny', 4238),\n",
       " ('years', 4132),\n",
       " ('makes', 4056),\n",
       " ('find', 4050),\n",
       " ('work', 4000),\n",
       " ('lot', 3989),\n",
       " ('actually', 3970),\n",
       " ('going', 3960),\n",
       " ('look', 3838),\n",
       " ('though', 3683),\n",
       " ('cant', 3653),\n",
       " ('another', 3643),\n",
       " ('part', 3636),\n",
       " ('old', 3577),\n",
       " ('nothing', 3567),\n",
       " ('want', 3545),\n",
       " ('every', 3491),\n",
       " ('cast', 3477),\n",
       " ('around', 3452),\n",
       " ('things', 3450),\n",
       " ('quite', 3412),\n",
       " ('pretty', 3407),\n",
       " ('seems', 3394),\n",
       " ('enough', 3371),\n",
       " ('thought', 3358),\n",
       " ('fact', 3336),\n",
       " ('got', 3284),\n",
       " ('director', 3254),\n",
       " ('take', 3206),\n",
       " ('music', 3167),\n",
       " ('give', 3155),\n",
       " ('horror', 3102),\n",
       " ('isnt', 3071),\n",
       " ('saw', 3058),\n",
       " ('young', 3050),\n",
       " ('role', 3040),\n",
       " ('whole', 3017),\n",
       " ('may', 3005),\n",
       " ('always', 3003),\n",
       " ('comedy', 2995),\n",
       " ('long', 2994),\n",
       " ('least', 2982),\n",
       " ('times', 2979),\n",
       " ('right', 2978),\n",
       " ('must', 2974),\n",
       " ('done', 2953),\n",
       " ('interesting', 2945),\n",
       " ('almost', 2938),\n",
       " ('without', 2926),\n",
       " ('series', 2904),\n",
       " ('world', 2884),\n",
       " ('come', 2881),\n",
       " ('minutes', 2867),\n",
       " ('bit', 2867),\n",
       " ('original', 2866),\n",
       " ('big', 2844),\n",
       " ('action', 2832),\n",
       " ('guy', 2829)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(X1).most_common()[0:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdeca7-3806-4db1-9b1f-b7b73d217441",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd695d-ac4b-487b-a36c-ab72a035f65b",
   "metadata": {},
   "source": [
    "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning Word Vectors for Sentiment Analysis. (June 2011). Retrieved November 2021 from http://www.aclweb.org/anthology/P11-1015 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1d3c4-f3a7-4b7c-ae74-b2588d4c53ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
