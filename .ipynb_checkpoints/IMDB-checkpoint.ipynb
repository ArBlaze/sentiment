{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973c5ac0-f057-4111-b26a-cd49e6b81880",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8660402-d904-4fae-b855-0e28ac8d1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "set_config(print_changed_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922dd47-c505-4877-b7ed-e12ac6d93d53",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e54ce6a6-23db-4fc4-b19b-1167a3da2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self, text, polarity):\n",
    "        self.text = text.translate(str.maketrans(' ', ' ',\n",
    "                                   string.punctuation)).replace(\"br\", \"\")\n",
    "        self.polarity = polarity\n",
    "\n",
    "\n",
    "class Features:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews.text\n",
    "        self.new_text = self.Stopwords()\n",
    "\n",
    "    def Stopwords(self):\n",
    "        sw_nltk = stopwords.words('english')\n",
    "        words = [word for word in self.reviews.split()\n",
    "                 if word.lower() not in sw_nltk]\n",
    "        new_text = \" \".join(words)\n",
    "        return new_text\n",
    "\n",
    "\n",
    "class Target:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews.polarity\n",
    "\n",
    "\n",
    "class Vectorization:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        # X_train, X_test CountVectorizer() transformations\n",
    "        self.X_train_vectors_count = self.count_vectorization()[0]\n",
    "        self.X_test_vectors_count = self.count_vectorization()[1]\n",
    "        self.Vectorizer_count = self.count_vectorization()[2]\n",
    "        # X_train, X_test TfidfVectorizer() transformation\n",
    "        self.X_train_vectors_tfidf = self.tfidf_vectorization()[0]\n",
    "        self.X_test_vectors_tfidf = self.tfidf_vectorization()[1]\n",
    "        self.Vectorizer_tfidf = self.tfidf_vectorization()[2]\n",
    "\n",
    "    def count_vectorization(self):\n",
    "        vectorizer = CountVectorizer()\n",
    "        X_train_vectors = vectorizer.fit_transform(self.X[0])\n",
    "        X_test_vectors = vectorizer.transform(self.X[1])\n",
    "        return (X_train_vectors, X_test_vectors, vectorizer)\n",
    "\n",
    "    def tfidf_vectorization(self):\n",
    "        vectorizer = TfidfVectorizer(lowercase=True, min_df=0.0001)\n",
    "        X_train_vectors = vectorizer.fit_transform(self.X[0])\n",
    "        X_test_vectors = vectorizer.transform(self.X[1])\n",
    "        return (X_train_vectors, X_test_vectors, vectorizer)\n",
    "\n",
    "\n",
    "class Logistic_Regression:\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = self.Model()\n",
    "\n",
    "    def Model(self):\n",
    "        clf_log = LogisticRegression(max_iter=1000)\n",
    "        clf_log.fit(self.X_train, self.y_train)\n",
    "        return (clf_log)\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.mean_score = self.mean_score()\n",
    "        self.f1_score = self.F1_score()\n",
    "\n",
    "    def mean_score(self):\n",
    "        return self.model.score(self.X_test, self.y_test)\n",
    "\n",
    "    def F1_score(self):\n",
    "        return f1_score(self.y_test, self.model.predict(self.X_test),\n",
    "                        average=None, labels=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf3ff9-66cd-4f03-ac67-2517d622804d",
   "metadata": {},
   "source": [
    "### Store negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e4f40b47-f965-45ff-8f1b-9e610fcefc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for links in os.listdir('./aclImdb_v1/aclImdb/test/neg'):\n",
    "    with open('./aclImdb_v1/aclImdb/test/neg/{}'.format(links),\n",
    "              encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            reviews.append(Review(line, 'negative'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1773428-d05d-4155-a1f9-8f598bda4d70",
   "metadata": {},
   "source": [
    "### Store positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a01228ec-69b1-44b2-b542-7fcb0c3c1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for links in os.listdir('./aclImdb_v1/aclImdb/test/pos'):\n",
    "    with open('./aclImdb_v1/aclImdb/test/pos/{}'.format(links),\n",
    "              encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            reviews.append(Review(line, 'positive'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4d297-c715-473f-83c7-2196ff51f287",
   "metadata": {},
   "source": [
    "### Shuffle the reviews so that it isn't directly positive reviews followed by negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "315681c4-eba9-4664-846a-b1d41b3eb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a585a9c-9e1c-46d8-982b-05d2c540a2b6",
   "metadata": {},
   "source": [
    "#### Seperate into X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "95651830-f239-44d1-9e39-fae9051edbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for line in reviews:\n",
    "    X.append(Features(line).new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6fdfc535-d3c6-44d4-98b9-6adb97321ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for line in reviews:\n",
    "    y.append(Target(line).reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018064e-87b2-4f0b-ad17-5a089b37ac31",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6cea7bbf-aac3-4f8d-a6ae-3e5fa67b1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd4e8c-f821-43ab-ade8-e1038eaa7a79",
   "metadata": {},
   "source": [
    "### Vectorize X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8c09f46c-1278-4a77-b98f-433ca10ef2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = Vectorization((X_train, X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb0992-7a90-4e8f-8993-3393dc49703f",
   "metadata": {},
   "source": [
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe89d3cb-9332-4a0c-a8f0-89b6f3c7264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_bow = vectorize.X_train_vectors_count\n",
    "X_test_vectors_bow = vectorize.X_test_vectors_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca33d94-e05e-4d4e-8912-fce08c8f4f79",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "66934541-611a-4b17-9c1f-dd2e148ad27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_tfidf = vectorize.X_train_vectors_tfidf\n",
    "X_test_vectors_tfidf = vectorize.X_test_vectors_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca342107-a7b6-4072-bc87-f78ffd3cb307",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e7b2-46ad-429f-b32f-a5425deab0a3",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "63ff20e2-5d43-48a9-9dbc-32dbd28c1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow = Logistic_Regression(X_train_vectors_bow, y_train).model\n",
    "model_tfidf = Logistic_Regression(X_train_vectors_tfidf, y_train).model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba680a66-d942-4b47-9348-a1ebb2a8eb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16750x41712 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1604814 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fdf81-4e83-4a52-b203-acbdf2f245cd",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa309ac-b379-43ab-baee-184f533213c7",
   "metadata": {},
   "source": [
    "#### Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9dc13cad-f8fb-443a-b72a-4492d096e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797575757575757\n",
      "0.8900606060606061\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print (Metrics(model_bow, X_test_vectors_bow, y_test).mean_score)\n",
    "print (Metrics(model_tfidf, X_test_vectors_tfidf, y_test).mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6ef30-362d-4fc1-bde3-a4f780165c36",
   "metadata": {},
   "source": [
    "#### F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a03cb85c-a6ff-4db0-ad40-dd8ceffef490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8804243  0.87908337]\n",
      "[0.89164974 0.88842416]\n"
     ]
    }
   ],
   "source": [
    "print (Metrics(model_bow, X_test_vectors_bow, y_test).f1_score)\n",
    "print (Metrics(model_tfidf, X_test_vectors_tfidf, y_test).f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042839ed-ce96-41d4-ba95-fe85650ad5a6",
   "metadata": {},
   "source": [
    "##### I want to improve our scores. There are a couple of things that we can do.\n",
    "* <s>Making each string lowercase</s>\n",
    "* <s>Removing punctuation</s>\n",
    "* <s>Removing common words such as \"and\", \"to\", \"or\", \"the\", \"is\", and more</s>\n",
    "* <s>Adding weights to words</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696feaf-b0cb-4e5c-9d5c-e68bd693f8b6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Save our model, and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d1866768-6e7d-4072-9e25-4233402f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_name = 'imdb.pkl'\n",
    "pickle.dump(model_tfidf, open('./webapp/model/{}'.format(model_name), 'wb'))\n",
    "loaded_model = pickle.load(open('./webapp/model/{}'.format(model_name), 'rb'))\n",
    "\n",
    "Vector = vectorize.Vectorizer_tfidf\n",
    "vector_name = 'tfidf1.pkl'\n",
    "pickle.dump(Vector, open('./webapp/model/{}'.format(vector_name), \"wb\"))\n",
    "tf1 = pickle.load(open('./webapp/model/{}'.format(vector_name), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b1f0d-6893-4964-8cc4-97d248dfd9a5",
   "metadata": {},
   "source": [
    "### Testing out pickled model and vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed60df-3f8c-4401-92ad-fc941ee3ffb6",
   "metadata": {},
   "source": [
    "#### Converting string into vectorizer form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "adf7a722-fd47-4ad6-b072-f2c018dd531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['bad bad bad bad bad bad', 'good good good good', 'bad good bad', 'This movie is awful. How can anyone spend their time with this garbage?!']\n",
    "tf1_vectored = tf1.transform(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84339ab-a8e0-476d-a246-e4855582b3ab",
   "metadata": {},
   "source": [
    "#### Predicting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0e8749cd-5133-4e97-802c-2e05bb118b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(tf1_vectored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdeca7-3806-4db1-9b1f-b7b73d217441",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd695d-ac4b-487b-a36c-ab72a035f65b",
   "metadata": {},
   "source": [
    "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning Word Vectors for Sentiment Analysis. (June 2011). Retrieved November 2021 from http://www.aclweb.org/anthology/P11-1015 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
